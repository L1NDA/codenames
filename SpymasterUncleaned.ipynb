{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gensim\n",
    "from nltk.corpus import words\n",
    "from functools import reduce\n",
    "import heapq\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #10 (got 400 columns instead of 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-11cc7d034655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2029\u001b[0m             \u001b[0;31m# Raise an exception ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minvalid_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m             \u001b[0;31m# Issue a warning ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Some errors were detected !\n    Line #10 (got 400 columns instead of 1)"
     ]
    }
   ],
   "source": [
    "wrds = np.genfromtxt('words.txt', delimiter=',', dtype=str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hollywood', 'well', 'foot', 'new york', 'spring', 'court', 'tube', 'point', 'tablet', 'slip', 'date', 'drill', 'lemon', 'bell', 'screen', 'fair', 'torch', 'state', 'match', 'iron', 'block', 'france', 'australia', 'limousine', 'stream', 'glove', 'nurse', 'leprechaun', 'play', 'tooth', 'arm', 'bermuda', 'diamond', 'whale', 'comic', 'mammoth', 'green', 'pass', 'missile', 'paste', 'drop', 'pheonix', 'marble', 'staff', 'figure', 'park', 'centaur', 'shadow', 'fish', 'cotton', 'egypt', 'theater', 'scale', 'fall', 'track', 'force', 'dinosaur', 'bill', 'mine', 'turkey', 'march', 'contract', 'bridge', 'robin', 'line', 'plate', 'band', 'fire', 'bank', 'boom', 'cat', 'shot', 'suit', 'chocolate', 'roulette', 'mercury', 'moon', 'net', 'lawyer', 'satellite', 'angel', 'spider', 'germany', 'fork', 'pitch', 'king', 'crane', 'trip', 'dog', 'conductor', 'part', 'bugle', 'witch', 'ketchup', 'press', 'spine', 'worm', 'alps', 'bond', 'pan', 'beijing', 'racket', 'cross', 'seal', 'aztec', 'maple', 'parachute', 'hotel', 'berry', 'soldier', 'ray', 'post', 'greece', 'square', 'mass', 'bat', 'wave', 'car', 'smuggler', 'england', 'crash', 'tail', 'card', 'horn', 'capital', 'fence', 'deck', 'buffalo', 'microscope', 'jet', 'duck', 'ring', 'train', 'field', 'gold', 'tick', 'check', 'queen', 'strike', 'kangaroo', 'spike', 'scientist', 'engine', 'shakespeare', 'wind', 'kid', 'embassy', 'robot', 'note', 'ground', 'draft', 'ham', 'war', 'mouse', 'center', 'china', 'bolt', 'spot', 'piano', 'pupil', 'plot', 'lion', 'police', 'head', 'litter', 'concert', 'mug', 'vacuum', 'atlantis', 'straw', 'switch', 'skyscraper', 'laser', 'scuba diver', 'africa', 'plastic', 'dwarf', 'lap', 'life', 'honey', 'horseshoe', 'unicorn', 'spy', 'pants', 'wall', 'paper', 'sound', 'ice', 'tag', 'web', 'fan', 'orange', 'temple', 'canada', 'scorpion', 'undertaker', 'mail', 'europe', 'soul', 'apple', 'pole', 'tap', 'mouth', 'ambulance', 'dress', 'icecream', 'rabbit', 'buck', 'agent', 'sock', 'nut', 'boot', 'ghost', 'oil', 'superhero', 'code', 'kiwi', 'hospital', 'saturn', 'film', 'button', 'snowman', 'helicopter', 'log', 'princess', 'time', 'cook', 'revolution', 'shoe', 'mole', 'spell', 'grass', 'washer', 'game', 'beat', 'hole', 'horse', 'pirate', 'link', 'dance', 'fly', 'pit', 'server', 'school', 'lock', 'brush', 'pool', 'star', 'jam', 'organ', 'berlin', 'face', 'luck', 'amazon', 'cast', 'gas', 'club', 'sink', 'water', 'chair', 'shark', 'jupiter', 'copper', 'jack', 'platypus', 'stick', 'olive', 'grace', 'bear', 'glass', 'row', 'pistol', 'london', 'rock', 'van', 'vet', 'beach', 'charge', 'port', 'disease', 'palm', 'moscow', 'pin', 'washington', 'pyramid', 'opera', 'casino', 'pilot', 'string', 'night', 'chest', 'yard', 'teacher', 'pumpkin', 'thief', 'bark', 'bug', 'mint', 'cycle', 'telescope', 'calf', 'air', 'box', 'mount', 'thumb', 'antarctica', 'trunk', 'snow', 'penguin', 'root', 'bar', 'file', 'hawk', 'battery', 'compound', 'slug', 'octopus', 'whip', 'america', 'ivory', 'pound', 'sub', 'cliff', 'lab', 'eagle', 'genius', 'ship', 'dice', 'hood', 'heart', 'novel', 'pipe', 'himalayas', 'crown', 'round', 'india', 'needle', 'shop', 'watch', 'lead', 'tie', 'table', 'cell', 'cover', 'czech', 'back', 'bomb', 'ruler', 'forest', 'bottle', 'space', 'hook', 'doctor', 'ball', 'bow', 'degree', 'rome', 'plane', 'giant', 'nail', 'dragon', 'stadium', 'flute', 'carrot', 'wake', 'fighter', 'model', 'tokyo', 'eye', 'mexico', 'hand', 'swing', 'key', 'alien', 'tower', 'poison', 'cricket', 'cold', 'knife', 'church', 'board', 'cloak', 'ninja', 'olympus', 'belt', 'light', 'death', 'stock', 'millionaire', 'day', 'knight', 'pie', 'bed', 'circle', 'rose', 'change', 'cap', 'triangle', 'chick']\n"
     ]
    }
   ],
   "source": [
    "words_upper = [\"Hollywood\", \"Well\", \"Foot\", \"New York\", \"Spring\", \"Court\", \"Tube\", \"Point\", \"Tablet\", \"Slip\", \"Date\", \"Drill\", \"Lemon\", \"Bell\", \"Screen\", \"Fair\", \"Torch\", \"State\", \"Match\", \"Iron\", \"Block\", \"France\", \"Australia\", \"Limousine\", \"Stream\", \"Glove\", \"Nurse\", \"Leprechaun\", \"Play\", \"Tooth\", \"Arm\", \"Bermuda\", \"Diamond\", \"Whale\", \"Comic\", \"Mammoth\", \"Green\", \"Pass\", \"Missile\", \"Paste\", \"Drop\", \"Pheonix\", \"Marble\", \"Staff\", \"Figure\", \"Park\", \"Centaur\", \"Shadow\", \"Fish\", \"Cotton\", \"Egypt\", \"Theater\", \"Scale\", \"Fall\", \"Track\", \"Force\", \"Dinosaur\", \"Bill\", \"Mine\", \"Turkey\", \"March\", \"Contract\", \"Bridge\", \"Robin\", \"Line\", \"Plate\", \"Band\", \"Fire\", \"Bank\", \"Boom\", \"Cat\", \"Shot\", \"Suit\", \"Chocolate\", \"Roulette\", \"Mercury\", \"Moon\", \"Net\", \"Lawyer\", \"Satellite\", \"Angel\", \"Spider\", \"Germany\", \"Fork\", \"Pitch\", \"King\", \"Crane\", \"Trip\", \"Dog\", \"Conductor\", \"Part\", \"Bugle\", \"Witch\", \"Ketchup\", \"Press\", \"Spine\", \"Worm\", \"Alps\", \"Bond\", \"Pan\", \"Beijing\", \"Racket\", \"Cross\", \"Seal\", \"Aztec\", \"Maple\", \"Parachute\", \"Hotel\", \"Berry\", \"Soldier\", \"Ray\", \"Post\", \"Greece\", \"Square\", \"Mass\", \"Bat\", \"Wave\", \"Car\", \"Smuggler\", \"England\", \"Crash\", \"Tail\", \"Card\", \"Horn\", \"Capital\", \"Fence\", \"Deck\", \"Buffalo\", \"Microscope\", \"Jet\", \"Duck\", \"Ring\", \"Train\", \"Field\", \"Gold\", \"Tick\", \"Check\", \"Queen\", \"Strike\", \"Kangaroo\", \"Spike\", \"Scientist\", \"Engine\", \"Shakespeare\", \"Wind\", \"Kid\", \"Embassy\", \"Robot\", \"Note\", \"Ground\", \"Draft\", \"Ham\", \"War\", \"Mouse\", \"Center\", \"China\", \"Bolt\", \"Spot\", \"Piano\", \"Pupil\", \"Plot\", \"Lion\", \"Police\", \"Head\", \"Litter\", \"Concert\", \"Mug\", \"Vacuum\", \"Atlantis\", \"Straw\", \"Switch\", \"Skyscraper\", \"Laser\", \"Scuba Diver\", \"Africa\", \"Plastic\", \"Dwarf\", \"Lap\", \"Life\", \"Honey\", \"Horseshoe\", \"Unicorn\", \"Spy\", \"Pants\", \"Wall\", \"Paper\", \"Sound\", \"Ice\", \"Tag\", \"Web\", \"Fan\", \"Orange\", \"Temple\", \"Canada\", \"Scorpion\", \"Undertaker\", \"Mail\", \"Europe\", \"Soul\", \"Apple\", \"Pole\", \"Tap\", \"Mouth\", \"Ambulance\", \"Dress\", \"IceCream\", \"Rabbit\", \"Buck\", \"Agent\", \"Sock\", \"Nut\", \"Boot\", \"Ghost\", \"Oil\", \"Superhero\", \"Code\", \"Kiwi\", \"Hospital\", \"Saturn\", \"Film\", \"Button\", \"Snowman\", \"Helicopter\", \"Log\", \"Princess\", \"Time\", \"Cook\", \"Revolution\", \"Shoe\", \"Mole\", \"Spell\", \"Grass\", \"Washer\", \"Game\", \"Beat\", \"Hole\", \"Horse\", \"Pirate\", \"Link\", \"Dance\", \"Fly\", \"Pit\", \"Server\", \"School\", \"Lock\", \"Brush\", \"Pool\", \"Star\", \"Jam\", \"Organ\", \"Berlin\", \"Face\", \"Luck\", \"Amazon\", \"Cast\", \"Gas\", \"Club\", \"Sink\", \"Water\", \"Chair\", \"Shark\", \"Jupiter\", \"Copper\", \"Jack\", \"Platypus\", \"Stick\", \"Olive\", \"Grace\", \"Bear\", \"Glass\", \"Row\", \"Pistol\", \"London\", \"Rock\", \"Van\", \"Vet\", \"Beach\", \"Charge\", \"Port\", \"Disease\", \"Palm\", \"Moscow\", \"Pin\", \"Washington\", \"Pyramid\", \"Opera\", \"Casino\", \"Pilot\", \"String\", \"Night\", \"Chest\", \"Yard\", \"Teacher\", \"Pumpkin\", \"Thief\", \"Bark\", \"Bug\", \"Mint\", \"Cycle\", \"Telescope\", \"Calf\", \"Air\", \"Box\", \"Mount\", \"Thumb\", \"Antarctica\", \"Trunk\", \"Snow\", \"Penguin\", \"Root\", \"Bar\", \"File\", \"Hawk\", \"Battery\", \"Compound\", \"Slug\", \"Octopus\", \"Whip\", \"America\", \"Ivory\", \"Pound\", \"Sub\", \"Cliff\", \"Lab\", \"Eagle\", \"Genius\", \"Ship\", \"Dice\", \"Hood\", \"Heart\", \"Novel\", \"Pipe\", \"Himalayas\", \"Crown\", \"Round\", \"India\", \"Needle\", \"Shop\", \"Watch\", \"Lead\", \"Tie\", \"Table\", \"Cell\", \"Cover\", \"Czech\", \"Back\", \"Bomb\", \"Ruler\", \"Forest\", \"Bottle\", \"Space\", \"Hook\", \"Doctor\", \"Ball\", \"Bow\", \"Degree\", \"Rome\", \"Plane\", \"Giant\", \"Nail\", \"Dragon\", \"Stadium\", \"Flute\", \"Carrot\", \"Wake\", \"Fighter\", \"Model\", \"Tokyo\", \"Eye\", \"Mexico\", \"Hand\", \"Swing\", \"Key\", \"Alien\", \"Tower\", \"Poison\", \"Cricket\", \"Cold\", \"Knife\", \"Church\", \"Board\", \"Cloak\", \"Ninja\", \"Olympus\", \"Belt\", \"Light\", \"Death\", \"Stock\", \"Millionaire\", \"Day\", \"Knight\", \"Pie\", \"Bed\", \"Circle\", \"Rose\", \"Change\", \"Cap\", \"Triangle\", \"Chick\"]\n",
    "\n",
    "words = [x.lower() for x in words_upper]\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'park', 'parachute', 'knife', 'cell', 'table', 'bridge', 'olive', 'yard'] ['gold', 'boot', 'spine', 'horseshoe', 'undertaker', 'point', 'comic', 'cast'] ['pole', 'scale', 'bed', 'change', 'pie', 'cook', 'revolution'] death\n"
     ]
    }
   ],
   "source": [
    "board = random.sample(words, 25)\n",
    "\n",
    "player1 = board[:9]\n",
    "player2 = board[9:17]\n",
    "neutral = board[17:24]\n",
    "assassin = board[24]\n",
    "\n",
    "print player1, player2, neutral, assassin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.013537  -0.028098   0.045745  ... -0.20906    0.051424   0.041097 ]\n",
      " [ 0.035629   0.19435   -0.46777   ...  0.38785    0.45448    0.38366  ]\n",
      " [ 0.048651  -0.36089    0.19444   ... -0.23537   -0.074001  -0.23663  ]\n",
      " ...\n",
      " [-0.028964  -0.76821    0.014601  ...  0.15432    0.076667   0.47699  ]\n",
      " [-0.31707    0.27897    0.13695   ... -0.32028    0.12964    0.069003 ]\n",
      " [-0.22935    0.12795   -0.30681   ... -0.10339    0.0040666  0.13925  ]]\n"
     ]
    }
   ],
   "source": [
    "positives = model[player1]\n",
    "print positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('glove.6B.300d.w2vformat.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: means will be discarded for subsequent trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no centroid defined for empty cluster.\n",
      "Try setting argument 'avoid_empty_clusters' to True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-6c8d2573d5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkclusterer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeansClusterer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLUSTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0massigned_clusters1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# kclusterer2 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/nltk/cluster/util.pyc\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(self, vectors, assign_clusters, trace)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# call abstract method to cluster the vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# assign the vectors to clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/nltk/cluster/kmeans.pyc\u001b[0m in \u001b[0;36mcluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mmeanss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/nltk/cluster/kmeans.pyc\u001b[0m in \u001b[0;36m_cluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# recalculate cluster means by computing the centroid of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mnew_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_centroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# measure the degree of change from the previous step for convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/nltk/cluster/kmeans.pyc\u001b[0m in \u001b[0;36m_centroid\u001b[0;34m(self, cluster, mean)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: no centroid defined for empty cluster.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Try setting argument \\'avoid_empty_clusters\\' to True\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS=3\n",
    "\n",
    "kclusterer1 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters1 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer2 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "# assigned_clusters2 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer3 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "# assigned_clusters3 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer4 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "# assigned_clusters4 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer5 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "# assigned_clusters5 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer6 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.euclidean_distance, repeats=25)\n",
    "# assigned_clusters6 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer7 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.euclidean_distance, repeats=25)\n",
    "# assigned_clusters7 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer8 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.euclidean_distance, repeats=25)\n",
    "# assigned_clusters8 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer9 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.euclidean_distance, repeats=25)\n",
    "# assigned_clusters9 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "# kclusterer10 = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.euclidean_distance, repeats=25)\n",
    "# assigned_clusters10 = kclusterer.cluster(positives, assign_clusters=True)\n",
    "\n",
    "print (assigned_clusters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsDict = collections.defaultdict()\n",
    "cluster_iteration = [assigned_clusters1, assigned_clusters2, assigned_clusters3, assigned_clusters4, assigned_clusters5, assigned_clusters6, assigned_clusters7, assigned_clusters8, assigned_clusters9, assigned_clusters10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        if i < j:\n",
    "        # same word\n",
    "            if i != j:\n",
    "                for iteration in cluster_iteration:\n",
    "                    if iteration[i] == iteration[j]:\n",
    "                        wordsDict[(i,j)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {(1, 2): 2, (7, 8): 6, (2, 5): 2, (2, 6): 5, (6, 7): 2, (4, 6): 6, (5, 6): 5, (2, 8): 3, (1, 4): 2, (2, 4): 8, (0, 6): 2, (3, 6): 2, (0, 4): 6, (0, 3): 2, (6, 8): 3, (0, 2): 3, (5, 8): 3, (3, 5): 7})\n"
     ]
    }
   ],
   "source": [
    "print wordsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill', 'spy', 'berlin', 'buffalo', 'king', 'flute', 'mount', 'center', 'bond']\n"
     ]
    }
   ],
   "source": [
    "print player1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0987985749343352e-07, 4.984995126724243, 1.4994384400779381e-07, 4.196436882019043, 1.7972598698179354e-07]\n",
      "{0: 2.0987985749343352e-07, 1: 19.939980506896973, 2: 1.4994384400779381e-07, 3: 8.392873764038086, 4: 1.7972598698179354e-07}\n",
      "{0: 1, 1: 4, 2: 1, 3: 2, 4: 1}\n",
      "[5.0188751220703125, 4.984995126724243, 2.0987985749343352e-07, 1.7972598698179354e-07]\n",
      "{0: 15.056625366210938, 1: 19.939980506896973, 2: 2.0987985749343352e-07, 3: 1.7972598698179354e-07}\n",
      "{0: 3, 1: 4, 2: 1, 3: 1}\n",
      "[1.7972598698179354e-07, 4.984995126724243, 5.0188751220703125, 2.0987985749343352e-07]\n",
      "{0: 1.7972598698179354e-07, 1: 19.939980506896973, 2: 15.056625366210938, 3: 2.0987985749343352e-07}\n",
      "{0: 1, 1: 4, 2: 3, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/40828929/sklearn-mean-distance-from-centroid-of-each-cluster\n",
    "\n",
    "kmeans1 = KMeans(n_clusters=5)\n",
    "clusters1 = kmeans1.fit_predict(positives)\n",
    "centroids1 = kmeans1.cluster_centers_\n",
    "\n",
    "mean_distances1 = {}\n",
    "mean_count1 = {}\n",
    "\n",
    "kmeans2 = KMeans(n_clusters=4)\n",
    "clusters2 = kmeans2.fit_predict(positives)\n",
    "centroids2 = kmeans2.cluster_centers_\n",
    "\n",
    "mean_distances2 = {}\n",
    "mean_count2 = {}\n",
    "\n",
    "kmeans3 = KMeans(n_clusters=4)\n",
    "clusters3 = kmeans3.fit_predict(positives)\n",
    "centroids3 = kmeans3.cluster_centers_\n",
    "\n",
    "mean_distances3 = {}\n",
    "mean_count3 = {}\n",
    "\n",
    "for i in range(5):\n",
    "    mean_distances1[i] = 0\n",
    "    mean_count1[i] = 0\n",
    "\n",
    "for i in range(4):\n",
    "    mean_distances2[i] = 0\n",
    "    mean_count2[i] = 0\n",
    "\n",
    "for i in range(4):\n",
    "    mean_distances3[i] = 0\n",
    "    mean_count3[i] = 0\n",
    "\n",
    "# go through clusters and calculate distance to centroid for each\n",
    "for i in range(9):\n",
    "    cluster1 = clusters1[i]\n",
    "    centroid1 = centroids1[cluster1]\n",
    "    distance1 = np.linalg.norm(centroid1-positives[i])\n",
    "    mean_distances1[cluster1] += distance1\n",
    "    mean_count1[cluster1] += 1\n",
    "    \n",
    "    cluster2 = clusters2[i]\n",
    "    centroid2 = centroids2[cluster2]\n",
    "    distance2 = np.linalg.norm(centroid2-positives[i])\n",
    "    mean_distances2[cluster2] += distance2\n",
    "    mean_count2[cluster2] += 1\n",
    "    \n",
    "    cluster3 = clusters3[i]\n",
    "    centroid3 = centroids3[cluster3]\n",
    "    distance3 = np.linalg.norm(centroid3-positives[i])\n",
    "    mean_distances3[cluster3] += distance3\n",
    "    mean_count3[cluster3] += 1\n",
    "\n",
    "mean_cluster1 = []\n",
    "mean_cluster2 = []\n",
    "mean_cluster3 = []\n",
    "\n",
    "# calculate mean\n",
    "for i in range(5):\n",
    "    mean_cluster1.append(mean_distances1[i]/mean_count1[i])\n",
    "    \n",
    "for i in range(4):\n",
    "    mean_cluster2.append(mean_distances2[i]/mean_count2[i])\n",
    "    \n",
    "for i in range(4):\n",
    "    mean_cluster3.append(mean_distances3[i]/mean_count3[i])\n",
    "    \n",
    "print mean_cluster1\n",
    "print mean_distances1\n",
    "print mean_count1\n",
    "\n",
    "print mean_cluster2\n",
    "print mean_distances2\n",
    "print mean_count2\n",
    "\n",
    "print mean_cluster3\n",
    "print mean_distances3\n",
    "print mean_count3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 3 4 3 1 2 1]\n",
      "[1 1 2 0 3 0 1 0 1]\n",
      "[1 1 3 2 0 2 1 2 1]\n",
      "['track', 'park', 'parachute', 'knife', 'cell', 'table', 'bridge', 'olive', 'yard']\n"
     ]
    }
   ],
   "source": [
    "print clusters1\n",
    "print clusters2\n",
    "print clusters3\n",
    "print player1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: hyperparameter for tightness of cluster vs number of clues\n",
    "# for now, using tights cluster with largest number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knife', 'table']\n"
     ]
    }
   ],
   "source": [
    "# finding tightest cluster\n",
    "\n",
    "minimum_value = 10\n",
    "words = []\n",
    "\n",
    "for index, value in enumerate(mean_cluster1):\n",
    "    if mean_count1[index] > 1 and value < minimum_value:\n",
    "        minimum_value = value\n",
    "        indices = [i for i, e in enumerate(clusters1) if e == index]\n",
    "        temp_words = []\n",
    "        for i in indices:\n",
    "            temp_words.append(player1[i])\n",
    "        words = temp_words\n",
    "        \n",
    "for index, value in enumerate(mean_cluster2):\n",
    "    if mean_count2[index] > 1 and value < minimum_value:\n",
    "        minimum_value = value\n",
    "        indices = [i for i, e in enumerate(clusters2) if e == index]\n",
    "        temp_words = []\n",
    "        for i in indices:\n",
    "            temp_words.append(player1[i])\n",
    "        words = temp_words\n",
    "        \n",
    "for index, value in enumerate(mean_cluster3):\n",
    "    if mean_count3[index] > 1 and value < minimum_value:\n",
    "        minimum_value = value\n",
    "        indices = [i for i, e in enumerate(clusters3) if e == index]\n",
    "        temp_words = []\n",
    "        for i in indices:\n",
    "            temp_words.append(player1[i])\n",
    "        words = temp_words\n",
    "        \n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4.984995126724243\n",
      "1\n",
      "1\n",
      "[1 1 0 3 4 3 1 2 1]\n",
      "['track', 'park', 'bridge', 'yard']\n"
     ]
    }
   ],
   "source": [
    "# other choice: find largest count\n",
    "\n",
    "combined = [0, clusters1, clusters2, clusters3]\n",
    "\n",
    "largest_count = 0\n",
    "count_value = 0\n",
    "count_index = 0\n",
    "trial = 0\n",
    "\n",
    "for index in range(5):\n",
    "    if mean_count1[index] > largest_count:\n",
    "        largest_count = mean_count1[index]\n",
    "        count_value = mean_cluster1[index]\n",
    "        count_index = index\n",
    "        trial = 1\n",
    "    if mean_count1[index] == largest_count:\n",
    "        if mean_cluster1[index] < count_value:\n",
    "            count_index = index\n",
    "            count_value = mean_cluster1[index]\n",
    "            trial = 1\n",
    "        \n",
    "for index in range(4):\n",
    "    if mean_count2[index] > largest_count:\n",
    "        largest_count = mean_count2[index]\n",
    "        count_value = mean_cluster2[index]\n",
    "        count_index = index\n",
    "        trial = 2\n",
    "    if mean_count2[index] == largest_count:\n",
    "        if mean_cluster2[index] < count_value:\n",
    "            count_index = index\n",
    "            count_value = mean_cluster2[index]\n",
    "            trial = 2\n",
    "            \n",
    "    if mean_count3[index] > largest_count:\n",
    "        largest_count = mean_count3[index]\n",
    "        count_value = mean_cluster3[index]\n",
    "        count_index = index\n",
    "        trial = 3\n",
    "    if mean_count3[index] == largest_count:\n",
    "        if mean_cluster3[index] < count_value:\n",
    "            count_index = index\n",
    "            count_value = mean_cluster3[index]\n",
    "            trial = 3\n",
    "\n",
    "print largest_count\n",
    "print count_value\n",
    "print count_index\n",
    "print trial\n",
    "\n",
    "words = []\n",
    "print combined[trial]\n",
    "indices = [i for i, e in enumerate(combined[trial]) if e == count_index]\n",
    "for i in indices:\n",
    "    words.append(player1[i])\n",
    "    \n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right-of-way\n"
     ]
    }
   ],
   "source": [
    "full_hint = model.most_similar(\n",
    "    positive=words,\n",
    "    negative=player2 + [assassin],\n",
    "    restrict_vocab=50000\n",
    ")\n",
    "\n",
    "hint = full_hint[0][0]\n",
    "print hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen', 'figure', 'tap', 'worm', 'night', 'park', 'fall', 'bell', 'olive', 'jet', 'turkey', 'tablet', 'shot', 'wake', 'limousine', 'note', 'button', 'ball', 'date', 'bolt', 'luck', 'berry', 'root', 'robin', 'giant']\n"
     ]
    }
   ],
   "source": [
    "print board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.013537 -0.028098  0.045745 ... -0.20906   0.051424  0.041097]\n",
      " [ 0.035629  0.19435  -0.46777  ...  0.38785   0.45448   0.38366 ]\n",
      " [ 0.048651 -0.36089   0.19444  ... -0.23537  -0.074001 -0.23663 ]\n",
      " ...\n",
      " [ 0.37224  -0.34577   0.35999  ... -0.091241 -0.62353   0.24756 ]\n",
      " [ 0.45979  -0.22301   0.18176  ... -0.21289   0.034345 -0.2813  ]\n",
      " [-0.095281  0.19231   0.35916  ...  0.3247   -0.17704   0.29431 ]]\n"
     ]
    }
   ],
   "source": [
    "guesser = model[board]\n",
    "print guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'roadway', 0.5434665083885193),\n",
       " (u'four-lane', 0.5191274285316467),\n",
       " (u'paralleling', 0.5083836913108826),\n",
       " (u'railroad', 0.5073590278625488),\n",
       " (u'two-lane', 0.5033497214317322),\n",
       " (u'terminus', 0.49456170201301575),\n",
       " (u'streetcar', 0.4910515546798706),\n",
       " (u'csx', 0.46943289041519165),\n",
       " (u'footpath', 0.45075321197509766),\n",
       " (u'alignment', 0.44879063963890076)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\n",
    "    positive=hint,\n",
    "    restrict_vocab=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.013537 -0.028098  0.045745 ... -0.20906   0.051424  0.041097]\n",
      " [ 0.035629  0.19435  -0.46777  ...  0.38785   0.45448   0.38366 ]\n",
      " [ 0.048651 -0.36089   0.19444  ... -0.23537  -0.074001 -0.23663 ]\n",
      " ...\n",
      " [ 0.37224  -0.34577   0.35999  ... -0.091241 -0.62353   0.24756 ]\n",
      " [ 0.45979  -0.22301   0.18176  ... -0.21289   0.034345 -0.2813  ]\n",
      " [-0.095281  0.19231   0.35916  ...  0.3247   -0.17704   0.29431 ]]\n"
     ]
    }
   ],
   "source": [
    "guesser_model = model[board]\n",
    "print guesser_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('track', 0.22234301), ('park', 0.16816987), ('parachute', -0.05921454), ('knife', 0.014912669), ('cell', -0.058619652), ('table', -0.07265681), ('bridge', 0.24698782), ('olive', 0.06442585), ('yard', 0.21688974), ('gold', -0.030817654), ('boot', -0.12772027), ('spine', -0.04533045), ('horseshoe', 0.05728756), ('undertaker', -0.009304337), ('point', 0.014696382), ('comic', -0.098254554), ('cast', -0.1071277), ('pole', 0.06081599), ('scale', -0.0070951656), ('bed', 0.029621579), ('change', -0.07725541), ('pie', -0.052529875), ('cook', -0.10230957), ('revolution', -0.097287275), ('death', -0.085452996)]\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for word in board:\n",
    "    prob = model.similarity(hint, word)\n",
    "    similarities.append((word, prob))\n",
    "\n",
    "print similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fc94622a3fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnoyIndexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mguesser_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/similarities/index.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     raise ImportError(\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;34m\"Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`"
     ]
    }
   ],
   "source": [
    "from gensim.similarities.index import AnnoyIndexer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "guesser_model = Word2Vec(board, min_count=1, seed=1)\n",
    "\n",
    "indexer = AnnoyIndexer(model, 4)\n",
    "guesser_model.most_similar(hint, topn=4, indexer=indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "don't know how to handle uri array([[-0.013537, -0.028098,  0.045745, ..., -0.20906 ,  0.051424,\n         0.041097],\n       [ 0.035629,  0.19435 , -0.46777 , ...,  0.38785 ,  0.45448 ,\n         0.38366 ],\n       [ 0.048651, -0.36089 ,  0.19444 , ..., -0.23537 , -0.074001,\n        -0.23663 ],\n       ...,\n       [ 0.37224 , -0.34577 ,  0.35999 , ..., -0.091241, -0.62353 ,\n         0.24756 ],\n       [ 0.45979 , -0.22301 ,  0.18176 , ..., -0.21289 ,  0.034345,\n        -0.2813  ],\n       [-0.095281,  0.19231 ,  0.35916 , ...,  0.3247  , -0.17704 ,\n         0.29431 ]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f327a514f695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mguesser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguesser_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/utils_any2vec.pyc\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'don\\'t know how to handle uri %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: don't know how to handle uri array([[-0.013537, -0.028098,  0.045745, ..., -0.20906 ,  0.051424,\n         0.041097],\n       [ 0.035629,  0.19435 , -0.46777 , ...,  0.38785 ,  0.45448 ,\n         0.38366 ],\n       [ 0.048651, -0.36089 ,  0.19444 , ..., -0.23537 , -0.074001,\n        -0.23663 ],\n       ...,\n       [ 0.37224 , -0.34577 ,  0.35999 , ..., -0.091241, -0.62353 ,\n         0.24756 ],\n       [ 0.45979 , -0.22301 ,  0.18176 , ..., -0.21289 ,  0.034345,\n        -0.2813  ],\n       [-0.095281,  0.19231 ,  0.35916 , ...,  0.3247  , -0.17704 ,\n         0.29431 ]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "guesser = gensim.models.KeyedVectors.load_word2vec_format(guesser_model, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
